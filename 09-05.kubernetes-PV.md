# Persistent Volume（持久化卷）
> 本文档介绍了 Kubernetes 中 PersistentVolume 的当前状态。建议您在阅读本文档前先熟悉 volume。   

# 介绍
> 1. 对于管理计算资源来说，管理存储资源明显是另一个问题。PersistentVolume 子系统为用户和管理员提供了一个 API，该 API 将如何提供存储的细节抽象了出来。为此，我们引入两个新的 API 资源：PersistentVolume 和 PersistentVolumeClaim。   
> 2. PersistentVolume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。   
> 3. PersistentVolumeClaim（PVC）是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或 只读多次模式挂载）。   
> 4. 虽然 PersistentVolumeClaims 允许用户使用抽象存储资源，但用户需要具有不同性质（例如性能）的 PersistentVolume 来解决不同的问题。集群管理员需要能够提供各种各样的 PersistentVolume，这些PersistentVolume 的大小和访问模式可以各有不同，但不需要向用户公开实现这些卷的细节。对于这些需求，StorageClass 资源可以实现。   
> 5. 请参阅[工作示例的详细过程](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/)。

# 卷和声明的生命周期
> PV 属于集群中的资源。PVC 是对这些资源的请求，也作为对资源的请求的检查。 PV 和 PVC 之间的相互作用遵循这样的生命周期：   

# 配置（Provision）
> 有两种方式来配置 PV：静态或动态。   

## 静态
> 集群管理员创建一些 PV。它们带有可供群集用户使用的实际存储的细节。它们存在于 Kubernetes API 中，可用于消费。   

## 动态
> 1. 当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim 时，集群可能会尝试动态地为 PVC 创建卷。此配置基于 StorageClasses：PVC 必须请求存储类，并且管理员必须创建并配置该类才能进行动态创建。声明该类为 "" 可以有效地禁用其动态配置。   
> 2. 要启用基于存储级别的动态存储配置，集群管理员需要启用 API server 上的 DefaultStorageClass 准入控制器。例如，通过确保 DefaultStorageClass 位于 API server 组件的 --admission-control 标志，使用逗号分隔的有序值列表中，可以完成此操作。有关 API server 命令行标志的更多信息，请检查 kube-apiserver 文档。   

# 绑定
> 1. 再动态配置的情况下，用户创建或已经创建了具有特定存储量的 PersistentVolumeClaim 以及某些访问模式。master 中的控制环路监视新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态调配 PV，则该环路将始终将该 PV 绑定到 PVC。否则，用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦 PV 和 PVC 绑定后，PersistentVolumeClaim 绑定是排他性的，不管它们是如何绑定的。 PVC 跟 PV 绑定是一对一的映射。   
> 2. 如果没有匹配的卷，声明将无限期地保持未绑定状态。随着匹配卷的可用，声明将被绑定。例如，配置了许多 50Gi PV的集群将不会匹配请求 100Gi 的PVC。将100Gi PV 添加到群集时，可以绑定 PVC。   

# 使用
> 1. Pod 使用声明作为卷。集群检查声明以查找绑定的卷并为集群挂载该卷。对于支持多种访问模式的卷，用户指定在使用声明作为容器中的卷时所需的模式。   
> 2. 用户进行了声明，并且该声明是绑定的，则只要用户需要，绑定的 PV 就属于该用户。用户通过在 Pod 的 volume 配置中包含 persistentVolumeClaim 来调度 Pod 并访问用户声明的 PV。   

# 持久化卷声明的保护
> 1. PVC 保护的目的是确保由 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话可能会导致数据丢失。   
> 2. 注意：当 pod 状态为 Pending 并且 pod 已经分配给节点或 pod 为 Running 状态时，PVC 处于活动状态。   
> 3. 当启用PVC 保护 alpha 功能时，如果用户删除了一个 pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 pod 使用。   
> 4. 您可以看到，当 PVC 的状态为 Teminatiing 时，PVC 受到保护，Finalizers 列表中包含 kubernetes.io/pvc-protection：   
```bash
kubectl described pvc hostpath
Name:          hostpath
Namespace:     default
StorageClass:  example-hostpath
Status:        Terminating
Volume:        
Labels:        <none>
Annotations:   volume.beta.kubernetes.io/storage-class=example-hostpath
               volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath
Finalizers:    [kubernetes.io/pvc-protection]
...
```

# 回收
> 用户用完 volume 后，可以从允许回收资源的 API 中删除 PVC 对象。PersistentVolume 的回收策略告诉集群在存储卷声明释放后应如何处理该卷。目前，volume 的处理策略有保留、回收或删除。

## 保留
> 保留回收策略允许手动回收资源。当 PersistentVolumeClaim 被删除时，PersistentVolume 仍然存在，volume 被视为“已释放”。但是由于前一个声明人的数据仍然存在，所以还不能马上进行其他声明。管理员可以通过以下步骤手动回收卷。   
> 1. 删除 PersistentVolume。在删除 PV 后，外部基础架构中的关联存储资产（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）仍然存在。   
> 2. 手动清理相关存储资产上的数据。   
> 3. 手动删除关联的存储资产，或者如果要重新使用相同的存储资产，请使用存储资产定义创建新的 PersistentVolume。   

## 回收
> 1. 如果存储卷插件支持，回收策略会在 volume上执行基本擦除（rm -rf / thevolume / *），可被再次声明使用。   
> 2. 但是，管理员可以使用如此处所述的 Kubernetes controller manager 命令行参数来配置自定义回收站 pod 模板。自定义回收站 pod 模板必须包含 volumes 规范，如下面的示例所示：   
```bash
apiVersion: v1
kind: Pod
metadata:
  name: pv-recycler
  namespace: default
spec:
  restartPolicy: Never
  volumes:
  - name: vol
    hostPath:
      path: /any/path/it/will/be/replaced
  containers:
  - name: pv-recycler
    image: "k8s.gcr.io/busybox"
    command: ["/bin/sh", "-c", "test -e /scrub && rm -rf /scrub/..?* /scrub/.[!.]* /scrub/*  && test -z \"$(ls -A /scrub)\" || exit 1"]
    volumeMounts:
    - name: vol
      mountPath: /scrub
```
> 3. 但是，volumes 部分的自定义回收站模块中指定的特定路径将被替换为正在回收的卷的特定路径。   

## 删除
> 对于支持删除回收策略的卷插件，删除操作将从 Kubernetes 中删除 PersistentVolume 对象，并删除外部基础架构（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）中的关联存储资产。动态配置的卷继承其 StorageClass，默认为 Delete。管理员应该根据用户的期望来配置 StorageClass，否则就必须要在 PV 创建后进行编辑或修补。请参阅更改 [PersistentVolume 的回收策略](https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/)。

# 扩展持久化卷声明
> 1. Kubernetes 1.8 增加了对扩展持久化存储卷的 Alpha 支持。在 v1.9 中，以下持久化卷支持扩展持久化卷声明：   
>> 1. gcePersistentDisk    
>> 2. awsElasticBlockStore   
>> 3. Cinder   
>> 4. glusterfs   
>> 5. rbd   
>> 
> 2. 管理员可以通过将 ExpandPersistentVolumes 特性门设置为true来允许扩展持久卷声明。管理员还应该启用[PersistentVolumeClaimResize 准入控制插件](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#persistentvolumeclaimresize)来执行对可调整大小的卷的其他验证。   
> 3. 一旦 PersistentVolumeClaimResize 准入插件已打开，将只允许其 allowVolumeExpansion 字段设置为 true 的存储类进行大小调整。   
```bash
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: gluster-vol-default
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: "http://192.168.10.100:8080"
  restuser: ""
  secretNamespace: ""
  secretName: ""
allowVolumeExpansion: true
```
> 4. 一旦功能门和前述准入插件打开后，用户就可以通过简单地编辑声明以请求更大的 PersistentVolumeClaim 卷。这反过来将触发 PersistentVolume 后端的卷扩展。   
> 5. 在任何情况下都不会创建新的 PersistentVolume 来满足声明。 Kubernetes 将尝试调整现有 volume 来满足声明的要求。   
> 6. 对于扩展包含文件系统的卷，只有在 ReadWrite 模式下使用 PersistentVolumeClaim 启动新的 Pod 时，才会执行文件系统调整大小。换句话说，如果正在扩展的卷在 pod 或部署中使用，则需要删除并重新创建要进行文件系统调整大小的pod。此外，文件系统调整大小仅适用于以下文件系统类型：   
>> 1. XFS   
>> 2. Ext3、Ext4   
>>
> 7. 注意：扩展 EBS 卷是一个耗时的操作。另外，每6个小时有一个修改卷的配额。

# 持久化卷类型
> PersistentVolume 类型以插件形式实现。Kubernetes 目前支持以下插件类型：   
>> 1. GCEPersistentDisk   
>> 2. AWSElasticBlockStore   
>> 3. AzureFile   
>> 4. AzureDisk   
>> 5. FC (Fibre Channel)   
>> 6. FlexVolume   
>> 7. Flocker   
>> 8. NFS   
>> 9. iSCSI   
>> 10. RBD (Ceph Block Device)   
>> 11. CephFS   
>> 12. Cinder (OpenStack block storage)   
>> 13. Glusterfs   
>> 14. VsphereVolume   
>> 15. Quobyte Volumes   
>> 16. HostPath （仅限于但节点测试—— 不会以任何方式支持本地存储，也无法在多节点集群中工作）   
>> 17. VMware Photon   
>> 18. Portworx Volumes   
>> 19. ScaleIO Volumes   
>> 20. StorageOS   
>>
> 原始块支持仅适用于以上这些插件。

# 持久化卷
> 每个 PV 配置中都包含一个 spec 规格字段和一个 status 卷状态字段。   
```bash
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2
```

# 容量
> 1. 通常，PV 将具有特定的存储容量。这是使用 PV 的容量属性设置的。查看 [Kubernetes 资源模型](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/resources.md) 以了解 capacity 预期。   
> 2. 目前，存储大小是可以设置或请求的唯一资源。未来的属性可能包括 IOPS、吞吐量等。   

# 卷模式
> 1. 在 v1.9 之前，所有卷插件的默认行为是在持久卷上创建一个文件系统。在 v1.9 中，用户可以指定一个 volumeMode，除了文件系统之外，它现在将支持原始块设备。 volumeMode 的有效值可以是“Filesystem”或“Block”。如果未指定，volumeMode 将默认为“Filesystem”。这是一个可选的 API 参数。   
> 2. 注意：该功能在 V1.9 中是 alpha的，未来可能会更改。   

# 访问模式
> 1. PersistentVolume 可以以资源提供者支持的任何方式挂载到主机上。如下表所示，供应商具有不同的功能，每个 PV 的访问模式都将被设置为该卷支持的特定模式。例如，NFS 可以支持多个读/写客户端，但特定的 NFS PV 可能以只读方式导出到服务器上。每个 PV 都有一套自己的用来描述特定功能的访问模式。   
> 2. 存储模式包括：   
>> 1. ReadWriteOnce——该卷可以被单个节点以读/写模式挂载   
>> 2. ReadOnlyMany——该卷可以被多个节点以只读模式挂载   
>> 3. ReadWriteMany——该卷可以被多个节点以读/写模式挂载   
>>
> 3. 在命令行中，访问模式缩写为：   
>> 1. RWO - ReadWriteOnce   
>> 2. ROX - ReadOnlyMany   
>> 3. RWX - ReadWriteMany   
>>
> 4. 重要！一个卷一次只能使用一种访问模式挂载，即使它支持很多访问模式。例如，GCEPersistentDisk 可以由单个节点作为 ReadWriteOnce 模式挂载，或由多个节点以 ReadOnlyMany 模式挂载，但不能同时挂载。    
   
Volume 插件|ReadWriteOnce|ReadOnlyMany|ReadWriteMany
----------|-------------|-------------|-------------
AWSElasticBlockStore|✓|-|-
AzureFile|✓|✓|✓
AzureDisk|✓|-|-
CephFS|✓|✓|✓
Cinder|✓|-|-
FC|✓|✓|-
FlexVolume|✓|✓|-
Flocker|✓|-|-
GCEPersistentDisk|✓|✓|-
Glusterfs|✓|✓|✓
HostPath|✓|-|-
iSCSI|✓|✓|-
PhotonPersistentDisk|✓|-|-
Quobyte|✓|✓|✓
NFS|✓|✓|✓
RBD|✓|✓|-
VsphereVolume|✓|-|- （当 pod 并列时有效）
PortworxVolume|✓|-|✓
ScaleIO|✓|✓|-
StorageOS|✓|-|-




